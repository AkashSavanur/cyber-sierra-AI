# CyberSierra AI App 

### [![Deploy Status](https://img.shields.io/badge/deployed-success-green?style=flat-square&logo=vercel)](https://cyber-sierra-ai.vercel.app/)

## ğŸŒ **Live Demo**: [https://cyber-sierra-ai.vercel.app/](https://cyber-sierra-ai.vercel.app/)
Two Datasets: The Titanic Dataset.csv and Data 3.xls (Network Log Data) is already uploaded and can be used for testing.

---

## ğŸš€ A full-stack AI-powered web app that allows users to:

- ğŸ“ Upload CSV/XLS files (multi-upload supported)
- ğŸ‘€ Preview top N rows from selected files
- ğŸ’¬ Ask questions in natural language and get responses from the data
- ğŸ” Reuse previous prompts from history
- ğŸ‘ğŸ‘ Provide feedback for LLM responses
- ğŸ“Š Chart rendering supported (auto-generated plots)

> Built using React, FastAPI, PandasAI, and OpenAI.

---

## ğŸ§ª Tech Stack

| Frontend            | Backend           | AI Layer         |
|---------------------|-------------------|------------------|
| React + MUI         | FastAPI           | PandasAI         |
| React Router        | Python 3.11+      | OpenAI API       |
| Axios, SweetAlert2  | Uvicorn, Pydantic | DuckDB (via PandasAI) |

---

## ğŸ›  Installation

### ğŸ“ Pre-requisites

Ensure you have the following installed:

- **Node.js** (v18+)
- **Python** (>= 3.11 recommended)
- `pip`, `venv`, and `git`

---

```bash
# Clone the repo
git clone https://github.com/AkashSavanur/cyber-sierra-AI.git
```

## ğŸ“¦ Backend Setup (FastAPI + PandasAI)

```bash
cd Backend

# 2. Create and activate virtual environment
python3.11 -m venv venv
source venv/bin/activate          # On Mac/Linux
# venv\Scripts\activate           # On Windows

# 3. Install dependencies
pip install setuptools wheel xlrd fastapi uvicorn pandas openpyxl python-dotenv pandasai pandasai-openai python-multipart typing_extensions

# May need to install Rust and Cargo, if encountering errors:
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# 4. Set up environment variables
touch .env                        # or `notepad .env` on Windows
# Paste your OpenAI key into the .env file:
# OPENAI_API_KEY=sk-proj-...

# 5. Run the server
uvicorn main:app --reload
```

âœ… Backend will be running at: http://127.0.0.1:8000

ğŸ’» Frontend Setup (React + MUI)
```bash
cd Frontend

# 1. Install Node modules
npm install

# 2. Start the frontend app
npm start
```

### âš™ï¸ API Endpoints (Backend)

| Method | Endpoint        | Description                             |
|--------|------------------|-----------------------------------------|
| POST   | `/api/upload`    | Upload one or more files                |
| GET    | `/api/files`     | List uploaded files                     |
| GET    | `/api/preview`   | Get top N rows of a selected file       |
| POST   | `/api/query`     | Ask prompt to LLM with file context     |
| POST   | `/api/feedback`  | Send feedback on LLM response           |
| GET    | `/api/history`   | Retrieve all past prompt responses      |
| GET    | `/api/charts/{chart_name}`   | Retrieve charts generated by LLM      |


### ğŸ“˜ Bonus Features
- Prompt reuse from history
- User feedback (ğŸ‘ / ğŸ‘)
- Auto-code reveal toggle (for transparency)
- Chart rendering (bar, line, pie auto-inferred)
- Query prefill from preview section

### ğŸ” Security Considerations
- .env used to securely store API keys
- .gitignore to prevent pushing data/, venv/, and .env files
- Axios and CORS configured securely
- OpenAI key can be revoked at any time if leaked
- Minimal trusted dependencies in requirements.txt

### ğŸ” Notes for Evaluators
- Uses your temporary OpenAI key: sk-proj-...
- Designed with extensibility and security in mind
- LLM errors are gracefully handled with fallback messaging

# ğŸš€ Built by Akash Savanur



